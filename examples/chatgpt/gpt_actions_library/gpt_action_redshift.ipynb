{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Action Library: AWS RedShift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This page provides an instruction & guide for developers building a GPT Action for a specific application. Before you proceed, make sure to first familiarize yourself with the following information: \n",
    "- [Introduction to GPT Actions](https://platform.openai.com/docs/actions)\n",
    "- [Introduction to GPT Actions Library](https://platform.openai.com/docs/actions/actions-library)\n",
    "- [Example of Building a GPT Action from Scratch](https://platform.openai.com/docs/actions/getting-started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution enables a GPT action to retrieve data from Redshift and perform data analysis.It uses AWS Functions, performing every action from AWS ecosystem and network. The middleware (AWS function) will perform the SQL query, wait for its completion and return the data as a file. The code is provided for information purpose only and should be modified to your needs.\n",
    "\n",
    "This solution uses the ability to [retrieve files in Actions](https://platform.openai.com/docs/actions/sending-files) and use them as if you had uploaded them directly to a conversation.\n",
    "\n",
    "This solution highlight a connection to Redshift serverless, the integration with a provisioned Redshift might differ slighltly to retrieve networks and set-up connection, the overall code and integration will be very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value + Example Business Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value**: Users can now leverage ChatGPT's natural language capability to connect directly to Redshift's DWH.\n",
    "\n",
    "**Example Use Cases**:\n",
    "- Data scientists can connect to tables and run data analyses using ChatGPT's Data Analysis\n",
    "- Citizen data users can ask basic questions of their transactional data\n",
    "- Users gain more visibility into their data & potential anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you get started, make sure that:\n",
    "- You have access to a Redshift environment\n",
    "- You have the right to deploy AWS function in the same VPC (Virtual Private Network)\n",
    "- Your AWS CLI is authenticated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Middleware Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required libraries\n",
    "- Install AWS CLI, required for AWS SAM ([docs](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html#getting-started-install-instructions))\n",
    "- Install AWS SAM CLI ([docs](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html))\n",
    "- Install Python\n",
    "- Install yq [docs](https://github.com/mikefarah/yq?tab=readme-ov-file#install)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middleware function\n",
    "\n",
    "You can either deploy directly this app [https://github.com/openai/redshift-middleware](https://github.com/openai/redshift-middleware), with your RedShift credentials as parameters or you can build your own SAM application (or any middleware), add the code of your function, and add psycog2 binary directly by following the steps in appendix.\n",
    "\n",
    "> This code is meant to be directional - while it should work out of the box, it is designed to be customized to your needs (see examples towards the end of this document).\n",
    "\n",
    "#### AWS SAM\n",
    "To ease the deployment of the lambda function and its dependencies, we're using SAM (Serverless Application Model), a framework that AWS supports with a CloudFormation set-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve VPC information\n",
    "\n",
    "We will need to connnect our function to Redshift, therefore we need to find the network used by Redshift. You can find this on your Redshift interface the AWS console, under Amazon Redshift Serverless > Workgroup configuration > <your_workgroup> > Data access, or through the CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"address\": \"default-workgroup.014498629922.us-east-1.redshift-serverless.amazonaws.com\",\n",
      "    \"port\": 5439,\n",
      "    \"SecurityGroupIds\": [\n",
      "        \"sg-027f8ddcf8733965c\"\n",
      "    ],\n",
      "    \"SubnetIds\": [\n",
      "        \"subnet-0645bb03fff5f1514\",\n",
      "        \"subnet-07b9339b8c119c45d\",\n",
      "        \"subnet-0355094e218ea2788\",\n",
      "        \"subnet-019a4d0836fb4024f\",\n",
      "        \"subnet-09f25a9cdc349c779\",\n",
      "        \"subnet-0c9ba9219bb590152\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! aws redshift-serverless get-workgroup --workgroup-name default-workgroup --query 'workgroup.{address: endpoint.address, port: endpoint.port, SecurityGroupIds: securityGroupIds, SubnetIds: subnetIds}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up AWS function\n",
    "\n",
    "Copy `env.sample.yaml` to `env.yaml` and replace with the values obtained above. You will need a Redshift user with access to your DB/schema.\n",
    "\n",
    "```\n",
    "git clone https://github.com/openai/redshift-middleware\n",
    "cd redshift-middleware\n",
    "cp env\n",
    "\n",
    "PARAM_FILE=\"env.yaml\"\n",
    "PARAMS=$(yq eval -o=json $PARAM_FILE | jq -r 'to_entries | map(\"\\(.key)=\\(.value|tostring)\") | join(\" \")')\n",
    "sam deploy --template-file template.yaml --stack-name redshift-middleware --capabilities CAPABILITY_IAM --parameter-overrides $PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the URL information, you can then try a cURL request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"openaiFileResponse\": [{\"name\": \"query_result.json\", \"mime_type\": \"application/json\", \"content\": \"W1sxMDAxLCAiQ3VzdG9tZXJfMTAwMSIsICJjdXN0b21lcjEwMDFAZXhhbXBsZS5jb20iLCAiNTU1LTAxMSIsICIxMjM0IEVsbSBTdCwgQ2l0eV8xLCBTdGF0ZV8xIiwgIlJldHVybmluZyJdLCBbMTAwMiwgIkN1c3RvbWVyXzEwMDIiLCAiY3VzdG9tZXIxMDAyQGV4YW1wbGUuY29tIiwgIjU1NS0wMTIiLCAiMTIzNCBFbG0gU3QsIENpdHlfMiwgU3RhdGVfMiIsICJOZXciXSwgWzEwMDMsICJDdXN0b21lcl8xMDAzIiwgImN1c3RvbWVyMTAwM0BleGFtcGxlLmNvbSIsICI1NTUtMDEzIiwgIjEyMzQgRWxtIFN0LCBDaXR5XzMsIFN0YXRlXzMiLCAiTmV3Il0sIFsxMDA0LCAiQ3VzdG9tZXJfMTAwNCIsICJjdXN0b21lcjEwMDRAZXhhbXBsZS5jb20iLCAiNTU1LTAxNCIsICIxMjM0IEVsbSBTdCwgQ2l0eV80LCBTdGF0ZV80IiwgIk5ldyJdLCBbMTAwNSwgIkN1c3RvbWVyXzEwMDUiLCAiY3VzdG9tZXIxMDA1QGV4YW1wbGUuY29tIiwgIjU1NS0wMTUiLCAiMTIzNCBFbG0gU3QsIENpdHlfNSwgU3RhdGVfMCIsICJSZXR1cm5pbmciXSwgWzEwMDYsICJDdXN0b21lcl8xMDA2IiwgImN1c3RvbWVyMTAwNkBleGFtcGxlLmNvbSIsICI1NTUtMDE2IiwgIjEyMzQgRWxtIFN0LCBDaXR5XzYsIFN0YXRlXzEiLCAiTmV3Il0sIFsxMDA3LCAiQ3VzdG9tZXJfMTAwNyIsICJjdXN0b21lcjEwMDdAZXhhbXBsZS5jb20iLCAiNTU1LTAxNyIsICIxMjM0IEVsbSBTdCwgQ2l0eV83LCBTdGF0ZV8yIiwgIk5ldyJdLCBbMTAwOCwgIkN1c3RvbWVyXzEwMDgiLCAiY3VzdG9tZXIxMDA4QGV4YW1wbGUuY29tIiwgIjU1NS0wMTgiLCAiMTIzNCBFbG0gU3QsIENpdHlfOCwgU3RhdGVfMyIsICJOZXciXSwgWzEwMDksICJDdXN0b21lcl8xMDA5IiwgImN1c3RvbWVyMTAwOUBleGFtcGxlLmNvbSIsICI1NTUtMDE5IiwgIjEyMzQgRWxtIFN0LCBDaXR5XzksIFN0YXRlXzQiLCAiUmV0dXJuaW5nIl0sIFsxMDEwLCAiQ3VzdG9tZXJfMTAxMCIsICJjdXN0b21lcjEwMTBAZXhhbXBsZS5jb20iLCAiNTU1LTAxMTAiLCAiMTIzNCBFbG0gU3QsIENpdHlfMCwgU3RhdGVfMCIsICJOZXciXV0=\"}]}"
     ]
    }
   ],
   "source": [
    "! curl -X POST https://10o5fvtsr1.execute-api.us-east-1.amazonaws.com/Prod/sql_statement/ \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{ \"sql_statement\": \"SELECT * FROM customers LIMIT 10\", \"workgroup_name\": \"default-workgroup\", \"database_name\": \"pap-db\" }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom GPT Instructions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've created a Custom GPT, copy the text below in the Instructions panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "**Context**: You are an expert at writing Redshift SQL queries. A user is going to ask you a question. \n",
    "\n",
    "**Instructions**:\n",
    "1. No matter the user's question, start by running `runQuery` operation using this query: \"SELECT table_name, column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE table_schema = 'public' ORDER BY table_name, ordinal_position;\" \n",
    "2. Convert the user's question into a SQL statement that leverages the step above and run the `runQuery` operation on that SQL statement to confirm the query works.\n",
    "3. Return back the query for the user to see\n",
    "\n",
    "**Additional Notes**: If the user says \"Let's get started\", explain they can ask a question they want answered about data that we have access to. If the user has no ideas, suggest that we have transactions data they can query - ask if they want you to query that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAPI Schema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've created a Custom GPT, copy the text below in the Actions panel.\n",
    "\n",
    "This expects a response that matches the file retrieval structure in our doc [here](https://platform.openai.com/docs/actions/sending-files) and passes in a `query` as a parameter to execute.\n",
    ">Make sure to switch the function app name based on your function deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "openapi: 3.1.0\n",
    "info:\n",
    "  title: SQL Execution API\n",
    "  description: API to execute SQL statements and return results as a file.\n",
    "  version: 1.0.0\n",
    "servers:\n",
    "  - url: {your_function_url}/Prod\n",
    "    description: Production server\n",
    "paths:\n",
    "  /sql_statement:\n",
    "    post:\n",
    "      operationId: executeSqlStatement\n",
    "      summary: Executes a SQL statement and returns the result as a file.\n",
    "      requestBody:\n",
    "        required: true\n",
    "        content:\n",
    "          application/json:\n",
    "            schema:\n",
    "              type: object\n",
    "              properties:\n",
    "                sql_statement:\n",
    "                  type: string\n",
    "                  description: The SQL statement to execute.\n",
    "                  example: SELECT * FROM customers LIMIT 10\n",
    "              required:\n",
    "                - sql_statement\n",
    "      responses:\n",
    "        '200':\n",
    "          description: The SQL query result as a JSON file.\n",
    "          content:\n",
    "            application/json:\n",
    "              schema:\n",
    "                type: object\n",
    "                properties:\n",
    "                  openaiFileResponse:\n",
    "                    type: array\n",
    "                    items:\n",
    "                      type: object\n",
    "                      properties:\n",
    "                        name:\n",
    "                          type: string\n",
    "                          description: The name of the file.\n",
    "                          example: query_result.json\n",
    "                        mime_type:\n",
    "                          type: string\n",
    "                          description: The MIME type of the file.\n",
    "                          example: application/json\n",
    "                        content:\n",
    "                          type: string\n",
    "                          description: The base64 encoded content of the file.\n",
    "                          format: byte\n",
    "                          example: eyJrZXkiOiJ2YWx1ZSJ9\n",
    "        '500':\n",
    "          description: Error response\n",
    "          content:\n",
    "            application/json:\n",
    "              schema:\n",
    "                type: object\n",
    "                properties:\n",
    "                  error:\n",
    "                    type: string\n",
    "                    description: Error message.\n",
    "                    example: Database query failed error details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No authentication was set-up, we recommend setting an authentication on your deployed function so only authenticated user can execute code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing psycog2 in your own directory before deploying:\n",
    "```\n",
    "mkdir -p lambda_layer/python\n",
    "pip install psycopg2-binary -t lambda_layer/python\n",
    "cd lambda_layer\n",
    "zip -r ../lambda_layer.zip .\n",
    "cd ..\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Are there integrations that you’d like us to prioritize? Are there errors in our integrations? File a PR or issue in our github, and we’ll take a look.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
